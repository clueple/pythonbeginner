{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745ebaa5-5ece-4048-8918-351aa9d559c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycantonese import characters_to_jyutping as ctj, segment\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b136aa6c-784a-4dd1-8aa7-8ec1a501b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_txt = r'廣東話 e 唔 easy呀?' #input text\n",
    "can_pat = r'[\\u4e00-\\u9fff]+$' #pattern recognizing Chinese characters\n",
    "num_pat = r'\\d' #pattern that recognizing jyutping with the tone as the stop word\n",
    "rep_num_pat = r'\\1 '# replacing the num_pat with the tone and a space that follows\n",
    "\n",
    "def is_cantonese(str):\n",
    "    return re.match(can_pat, str)\n",
    "\n",
    "def split_jyut(str):\n",
    "    \"\"\" convert a Cantonese term's jyutping into a list of jyutping \n",
    "    e.g. 'gwong2dung1waa2'  -> ['gwong2','dung1','waa2']\n",
    "    \"\"\"\n",
    "    return re.sub(num_pat, rep_num_pat,str).split()\n",
    "\n",
    "def flat_list(nested):\n",
    "    \"\"\" flatten a nested list containing sublists \n",
    "    e.g. [['a','b'],['c','d'],['e']] -> ['a','b','c','d','e']\n",
    "    \"\"\"\n",
    "    #return [item for sublist in nested for item in sublist]\n",
    "    return [item for sublist in nested for item in (sublist if isinstance(sublist, list) else [sublist])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0976f4b0-5f04-4639-90fb-fc622419fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CantoneseTokenize:\n",
    "    def __init__(self, source_text):\n",
    "        self.tokens = self.tokenize(source_text)\n",
    "        self.word_tokens = flat_list([list(i) if is_cantonese(i) else i for i in segment(source_text)])\n",
    "        #self.jyut_tokens = [i[1] if is_cantonese(i[0]) else i[0]  for i in self.tokens]\n",
    "        self.jyut_tokens = [ctj(i)[0][1] if is_cantonese(i) else i for i in self.word_tokens]\n",
    "        \n",
    "        \n",
    "    def tokenize(self, source_text):\n",
    "        \"\"\" Tokenize the source_text using pycantonese \"\"\"\n",
    "        try: \n",
    "            tokens = ctj(source_text)\n",
    "            return tokens\n",
    "        except:\n",
    "            print(f\"error during tokenization {e}\")\n",
    "            return []\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b0445-5031-47fc-9049-90ad33152e98",
   "metadata": {},
   "source": [
    "# **preview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a090763b-9438-4ef4-b253-569c9a085396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ths is the tokens:\n",
      "[('廣東話', 'gwong2dung1waa2'), ('e', 'e1'), ('唔', 'm4'), ('easy', None), ('呀', 'aa4'), ('?', None)]\n",
      "This is the jyut_tokens:\n",
      "['gwong2', 'dung1', 'waa6', 'e', 'm4', 'easy', 'aa4', '?']\n",
      "This is the word_tokens:\n",
      "['廣', '東', '話', 'e', '唔', 'easy', '呀', '?']\n",
      "The index 3 is e\n"
     ]
    }
   ],
   "source": [
    "sent_tok = CantoneseTokenize(source_text=src_txt)\n",
    "tokens = sent_tok.tokens\n",
    "jyut_tokens = sent_tok.jyut_tokens\n",
    "word_tokens = sent_tok.word_tokens\n",
    "\n",
    "print(f\"\"\"Ths is the tokens:\\n{tokens}\n",
    "This is the jyut_tokens:\\n{jyut_tokens}\n",
    "This is the word_tokens:\\n{word_tokens}\"\"\")\n",
    "print(f\"The index 3 is {word_tokens[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4999c5-bec8-4242-a523-8478126f7f6c",
   "metadata": {},
   "source": [
    "# **Explaining how to flatten a list of sublist with for-loops**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da2190f-d755-47a7-a67a-80a12e204cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['廣', '東', '話', 'e', '唔', 'easy', '呀', '?']\n"
     ]
    }
   ],
   "source": [
    "tword_tokens = [['廣', '東', '話'], 'e', ['唔'], 'easy', ['呀'], '?']\n",
    "flattened_word_tokens = []\n",
    "for item in tword_tokens:\n",
    "    if isinstance(item, list):\n",
    "        flattened_word_tokens.extend(item)\n",
    "    else:\n",
    "        flattened_word_tokens.append(item)\n",
    "print(flattened_word_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f48afd-e7af-4ec8-9674-977bb405f6a3",
   "metadata": {},
   "source": [
    "# **Explaining how to flatten a list of sublist with list comprehension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c955ac36-ec07-4652-86ce-c043bf0d91eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['廣', '東', '話', 'e', '唔', 'easy', '呀', '?']\n"
     ]
    }
   ],
   "source": [
    "tword_tokens = [['廣', '東', '話'], 'e', ['唔'], 'easy', ['呀'], '?']\n",
    "flattened_word_tokens = [item for sublist in tword_tokens for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "print(flattened_word_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d88ad6e-bed3-488f-9277-d652c1f8989e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[('廣', 'gwong2')]\",\n",
       " \"[('東', 'dung1')]\",\n",
       " \"[('話', 'waa6')]\",\n",
       " 'e',\n",
       " \"[('唔', 'm4')]\",\n",
       " 'easy',\n",
       " \"[('呀', 'aa4')]\",\n",
       " '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [f\"{ctj(i)}\" if is_cantonese(i) else i for i in word_tokens] \n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc75bc62-4529-43a8-82d2-22759dd1f600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['廣', '東', '話', 'e', '唔', 'easy', '呀', '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_list = flat_list([list(i) if is_cantonese(i) else i for i in segment(src_txt)])\n",
    "w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7731ec6f-6061-4ec7-8f53-fc402504fe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gwong2', 'dung1', 'waa6', 'e1', 'm4', None, 'aa4', None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_list = [ctj(i)[0][1] for i in w_list]\n",
    "j_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05ff47-7f00-40c4-acc0-590027e429e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
